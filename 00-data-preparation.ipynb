{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_RATIO = 0.1\n",
    "\n",
    "def prepare_csv(seed=999):\n",
    "    data = pd.read_csv(\"data.csv\")[:1000]\n",
    "    \n",
    "    idx = data.index.values\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(idx)\n",
    "    \n",
    "    val_size = int(len(idx) * VAL_RATIO)\n",
    "    \n",
    "    data.iloc[idx[:val_size]].to_csv(\n",
    "        \"cache/dataset_val.csv\", index=False)\n",
    "    data.iloc[idx[val_size:2*val_size]].to_csv(\n",
    "        \"cache/dataset_test.csv\", index=False)\n",
    "    data.iloc[idx[2*val_size:]].to_csv(\n",
    "        \"cache/dataset_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "NLP = spacy.load('en')\n",
    "MAX_CHARS = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(comment):\n",
    "    comment = re.sub(\n",
    "        r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", \n",
    "        str(comment))\n",
    "    comment = re.sub(r\"[ ]+\", \" \", comment)\n",
    "    comment = re.sub(r\"\\!+\", \"!\", comment)\n",
    "    comment = re.sub(r\"\\,+\", \",\", comment)\n",
    "    comment = re.sub(r\"\\?+\", \"?\", comment)\n",
    "    if (len(comment) > MAX_CHARS):\n",
    "        comment = comment[:MAX_CHARS]\n",
    "    return [\n",
    "        x.text for x in NLP.tokenizer(comment) if x.text != \" \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from torchtext import data\n",
    "LOGGER = logging.getLogger(\"reviews_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(fix_length=100, lower=False, vectors=None):\n",
    "    \n",
    "    if vectors is not None:\n",
    "        # pretrain vectors only supports all lower cases\n",
    "        lower = True\n",
    "    \n",
    "    LOGGER.debug(\"Preparing CSV files...\")\n",
    "    prepare_csv()\n",
    "    \n",
    "    review_text = data.Field(\n",
    "        sequential=True,\n",
    "        fix_length=fix_length,\n",
    "        tokenize=tokenizer,\n",
    "        pad_first=True,\n",
    "        dtype=torch.float64,\n",
    "        lower=lower\n",
    "    )\n",
    "    \n",
    "    theme = data.Field(\n",
    "                use_vocab=True, \n",
    "                sequential=False, \n",
    "                dtype=torch.float64)\n",
    "    \n",
    "    meta_id = data.Field(\n",
    "                use_vocab=True, sequential=False, \n",
    "                dtype=torch.float64)\n",
    "    \n",
    "    fields=[\n",
    "            ('meta_id', meta_id),\n",
    "            ('review_text', review_text),\n",
    "            ('theme', theme)]\n",
    "    \n",
    "    LOGGER.debug(\"Reading train csv file...\")\n",
    "    train, val = data.TabularDataset.splits(\n",
    "        path='cache/', format='csv', skip_header=True,\n",
    "        train='dataset_train.csv', validation='dataset_val.csv',\n",
    "        fields = fields\n",
    "        )\n",
    "    \n",
    "    LOGGER.debug(\"Reading test csv file...\")\n",
    "    test = data.TabularDataset(\n",
    "        path='cache/dataset_test.csv', format='csv', \n",
    "        skip_header=True, fields=fields)\n",
    "    \n",
    "    LOGGER.debug(\"Building vocabulary...\")\n",
    "    \n",
    "    review_text.build_vocab(\n",
    "        train, val, test,\n",
    "        max_size=30000,\n",
    "        min_freq=5,\n",
    "        vectors=vectors\n",
    "    )\n",
    "\n",
    "    meta_id.build_vocab(\n",
    "        train, val, test,\n",
    "        max_size=float('inf'),\n",
    "        min_freq=0,\n",
    "    )\n",
    "    \n",
    "    theme.build_vocab(\n",
    "        train, val, test,\n",
    "        max_size=10,\n",
    "        min_freq=0,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    LOGGER.debug(\"Done preparing the datasets\")\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iterator(dataset, batch_size, train=True, shuffle=True, repeat=False):\n",
    "    \n",
    "    dataset_iter = data.Iterator(\n",
    "        dataset, batch_size=batch_size, device='cuda',\n",
    "        train=train, shuffle=shuffle, repeat=repeat,\n",
    "        \n",
    "        sort_key = lambda x: len(x.review_text),\n",
    "        sort_within_batch=False,\n",
    "        sort=True\n",
    "    )\n",
    "    return dataset_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ff = val_dataset.fields['review_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 32]) torch.Size([32, 1])\n",
      "torch.Size([100, 32]) torch.Size([32, 1])\n",
      "torch.Size([100, 32]) torch.Size([32, 1])\n",
      "torch.Size([100, 4]) torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "for examples in get_iterator(\n",
    "            val_dataset, 32, train=False,\n",
    "            shuffle=False, repeat=False,\n",
    "        ):\n",
    "    x = examples.review_text # (fix_length, batch_size) Tensor\n",
    "    y = torch.stack([examples.theme], dim=1)\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
