{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import get_iterator, get_dataset\n",
    "from classifiers import theme_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe \n",
    "GLOVE_EMBEDDING = GloVe(name=\"6B\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, review_text_FIELD, theme_FIELD = get_dataset(vectors = \n",
    "                                                                                       GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_iter = get_iterator(train_dataset, batch_size, train=True, shuffle=False, repeat=False)\n",
    "val_iter = get_iterator(val_dataset, batch_size, train=False, shuffle=False, repeat=False)\n",
    "test_iter = get_iterator(test_dataset, batch_size, train=False, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = list(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> predictable and boring <eos> | other\n",
      "<sos> very interesting . <eos> | other\n",
      "<sos> not scary . <eos> | other\n",
      "<sos> awful <unk> disturbing <eos> | other\n",
      "<sos> same story . <eos> | plot\n",
      "<sos> see this . <eos> | other\n",
      "<sos> good movie . <eos> | other\n",
      "<sos> worth the watch <eos> | other\n",
      "<sos> what a ride <eos> | other\n",
      "<sos> ¥ â ? <eos> | other\n"
     ]
    }
   ],
   "source": [
    "batch = val_list[50]\n",
    "x = batch.review_text.transpose(1, 0).int()[:10]\n",
    "y = batch.theme.int()\n",
    "\n",
    "for idx in range(x.shape[0]):\n",
    "    #print(x.shape, y.shape)\n",
    "    print(\"{} | {}\".format(' '.join([train_dataset.fields['review_text'].vocab.itos[_] for _ in x[idx]]),\n",
    "         train_dataset.fields['theme'].vocab.itos[y[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review_text_FIELD.vocab.vectors.shape, len(review_text_FIELD.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'other', 'plot', 'acting', 'effect', 'production']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_FIELD.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20004, 5, 300, torch.Size([20004, 300]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = review_text_FIELD.vocab.vectors.shape[0]\n",
    "label_size = len(theme_FIELD.vocab) - 1\n",
    "emb_dim = review_text_FIELD.vocab.vectors.shape[1]\n",
    "vectors = train_dataset.fields[\"review_text\"].vocab.vectors\n",
    "hidden_dim = 1024\n",
    "layers = 2\n",
    "dropout = .5\n",
    "\n",
    "vocab_size, label_size, emb_dim, vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 ninp = vocab_size, \n",
    "                 linp = label_size, \n",
    "                 emb_dim = emb_dim, \n",
    "                 emb_lab = 20,\n",
    "                 nhid = hidden_dim, \n",
    "                 nout = vocab_size, \n",
    "                 nlayers = layers, \n",
    "                 dropout = dropout, \n",
    "                 vectors = vectors,\n",
    "                 pretrained = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ninp = ninp\n",
    "        self.linp = linp\n",
    "        self.emb_dim = emb_dim\n",
    "        self.emb_lab = emb_lab\n",
    "        self.nhid = nhid\n",
    "        self.nout = nout\n",
    "        self.nlayers = nlayers\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.word_embedding = nn.Embedding(ninp, emb_dim)\n",
    "        self.label_embedding = nn.Embedding(linp, emb_lab)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim + emb_lab, nhid, nlayers, dropout=dropout)\n",
    "        self.rnn.flatten_parameters()\n",
    "        self.decoder = nn.Linear(nhid, nout)\n",
    "\n",
    "        if pretrained:\n",
    "            self.word_embedding.weight.data.copy_(vectors)\n",
    "            self.word_embedding.from_pretrained(GLOVE_EMBEDDING.vectors)\n",
    "            \n",
    "        self.init_weights()    \n",
    "            \n",
    "    def init_weights(self):\n",
    "        initrange = .1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, reviews, labels, hidden):\n",
    "        #print('R.shape', reviews.shape)\n",
    "        R = self.word_embedding(reviews)\n",
    "        L = self.label_embedding(labels)\n",
    "        L = torch.cat([L.unsqueeze(0)]*R.shape[0])\n",
    "        X = torch.cat([R, L], -1)\n",
    "        #print('X.shape', X.shape)\n",
    "        \n",
    "        X = self.drop(X)\n",
    "        X, hidden = self.rnn(X, hidden)\n",
    "        X = self.drop(X)\n",
    "        #print('X.shape', X.shape)\n",
    "        #X = X.view(X.size(0)*X.size(1), X.size(2))\n",
    "        #print('X.shape', X.shape)\n",
    "        \n",
    "        X = self.decoder(X)\n",
    "        #print('X.shape', X.shape)\n",
    "        log_probs = torch.softmax(X, -1)\n",
    "        return log_probs, hidden\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_source, criterion):\n",
    "    model.eval()\n",
    "    total_loss_e = 0\n",
    "    total_number_of_words = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_source):\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            hidden = None\n",
    "            if batch.shape[0] > 2:\n",
    "                data, targets = batch[1:-1,:], batch[2:,:]\n",
    "                \n",
    "                output, hidden = model(data, labels, hidden)\n",
    "                output_flat = output.contiguous().view(-1, vocab_size)\n",
    "                \n",
    "                batch_loss = criterion(output_flat, targets.contiguous().view(-1)).detach().item()\n",
    "\n",
    "                number_of_words = data.shape[0] * data.shape[1]\n",
    "                total_loss_e += batch_loss\n",
    "                total_number_of_words += number_of_words\n",
    "\n",
    "                hidden = repackage_hidden(hidden)\n",
    "            \n",
    "    return total_loss_e / total_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, ep0, epN, train_iter, dev_iter, optimizer, criterion, \n",
    "          max_grad_norm, model_name, best_ppl = float('inf')):\n",
    "    \n",
    "    best_ppl = best_ppl\n",
    "    \n",
    "    len_train_iter = len(train_iter)\n",
    "    for epoch in range(ep0, epN):\n",
    "        model.train()\n",
    "        total_loss_e = 0\n",
    "        total_number_of_words = 0 \n",
    "        \n",
    "        for i, batch in enumerate(train_iter):\n",
    "\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            hidden = None\n",
    "            if batch.shape[0] > 2:\n",
    "                data, targets = batch[1:-1,:], batch[2:,:]\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output, hidden = model(data, labels, hidden)\n",
    "                hidden = repackage_hidden(hidden)\n",
    "\n",
    "                output_flat = output.contiguous().view(-1, vocab_size)\n",
    "                batch_loss = criterion(output_flat, targets.contiguous().view(-1))\n",
    "                number_of_words = data.shape[0] * data.shape[1]\n",
    "\n",
    "                total_loss_e += batch_loss.detach().item()\n",
    "                total_number_of_words += number_of_words\n",
    "            \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                if i % 500 == 0:\n",
    "                    cur_loss = batch_loss.item() / number_of_words #np.mean(total_loss_e)#\n",
    "                    tr_ppl_print = np.exp(cur_loss)\n",
    "                    print(\"| epoch {:3d} | batch {} / {} | train_loss {} | train_ppl {}\".format(\n",
    "                            epoch, i, len_train_iter, \n",
    "                            np.round(cur_loss, 3), np.round(tr_ppl_print, 3)))\n",
    "\n",
    "                #gc.collect()\n",
    "                #torch.cuda.empty_cache()\n",
    "                \n",
    "                if i % 4999 == 1: #len_train_iter - 1:\n",
    "                    cur_loss = total_loss_e / total_number_of_words #np.mean(total_loss_e) #\n",
    "                    tr_ppl_print = np.exp(cur_loss)\n",
    "                    gc.collect()\n",
    "                    #torch.cuda.empty_cache()\n",
    "                    val_loss_eval = evaluate(model, dev_iter, criterion)\n",
    "                    val_ppl_print = np.exp(val_loss_eval)\n",
    "                    \n",
    "                    template = \"| epoch {:3d} | batch {} / {} | train_loss {} | train_ppl {} | val_loss {} | val_ppl {}\"\n",
    "                    print(template.format(\n",
    "                            epoch, i, len_train_iter, \n",
    "                            np.round(cur_loss, 3), np.round(tr_ppl_print, 3), \n",
    "                            np.round(val_loss_eval, 3), np.round(val_ppl_print, 3)))\n",
    "\n",
    "                    if val_ppl_print < best_ppl :\n",
    "                        print('old best ppl {} new best ppl {}'.format(best_ppl, val_ppl_print))\n",
    "                        best_ppl = val_ppl_print\n",
    "                        best_model_name = 'best_model_{}_{}.model'.format(model_name, best_ppl)\n",
    "                        print('save model...', best_model_name)\n",
    "                        with open(best_model_name, 'wb') as file:\n",
    "                            torch.save(model, file) \n",
    "\n",
    "                    gc.collect()\n",
    "                    model.train()\n",
    "                    \n",
    "                if i == 10000: break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('./best_model_base_model_ppl_15624.350597914712.model', 'rb') as file:\n",
    "#    model = torch.load(file)#BaseModel().cuda()\n",
    "#    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('best_model_name', 'rb') as file:\n",
    "#    model = torch.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel(pretrained=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (word_embedding): Embedding(20004, 300)\n",
       "  (label_embedding): Embedding(5, 20)\n",
       "  (rnn): LSTM(320, 1024, num_layers=2, dropout=0.5)\n",
       "  (decoder): Linear(in_features=1024, out_features=20004, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement PPL\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss(reduction='sum',\n",
    "                       ignore_index=train_dataset.fields[\"review_text\"].vocab.stoi['<pad>']).cuda()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.exp(evaluate(model, val_list, criterion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,\n",
    "      ep0 = 1,\n",
    "      epN = 3,\n",
    "      train_iter = train_iter,\n",
    "      dev_iter = val_iter,\n",
    "      optimizer = optimizer,\n",
    "      criterion = criterion,\n",
    "      max_grad_norm = 10,\n",
    "      model_name = 'base_model_ppl',\n",
    "      best_ppl = float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | batch 500 / 10981 | train_loss 9.679 | train_ppl 15979.841\n",
      "| epoch   0 | batch 1000 / 10981 | train_loss 9.716 | train_ppl 16585.358\n",
      "| epoch   0 | batch 1500 / 10981 | train_loss 9.762 | train_ppl 17353.177\n",
      "| epoch   0 | batch 2000 / 10981 | train_loss 9.759 | train_ppl 17316.581\n",
      "| epoch   0 | batch 2500 / 10981 | train_loss 9.676 | train_ppl 15925.449\n",
      "| epoch   0 | batch 2500 / 10981 | train_loss 9.706 | train_ppl 16414.26 | val_loss 9.757 | val_ppl 17281.964\n",
      "old best ppl 26821.121 new best ppl 17281.963849636402\n",
      "save model... best_model_base_model_ppl_17281.963849636402.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BaseModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | batch 3000 / 10981 | train_loss 9.856 | train_ppl 19077.485\n",
      "| epoch   0 | batch 3500 / 10981 | train_loss 9.802 | train_ppl 18062.801\n",
      "| epoch   0 | batch 4000 / 10981 | train_loss 9.748 | train_ppl 17117.231\n",
      "| epoch   0 | batch 4500 / 10981 | train_loss 9.769 | train_ppl 17486.194\n",
      "| epoch   0 | batch 5000 / 10981 | train_loss 9.771 | train_ppl 17512.124\n",
      "| epoch   0 | batch 5500 / 10981 | train_loss 9.777 | train_ppl 17618.156\n",
      "| epoch   0 | batch 6000 / 10981 | train_loss 9.776 | train_ppl 17601.243\n",
      "| epoch   0 | batch 6500 / 10981 | train_loss 9.725 | train_ppl 16723.1\n",
      "| epoch   0 | batch 7000 / 10981 | train_loss 9.739 | train_ppl 16962.161\n",
      "| epoch   0 | batch 7500 / 10981 | train_loss 9.738 | train_ppl 16946.575\n",
      "| epoch   0 | batch 8000 / 10981 | train_loss 9.742 | train_ppl 17013.963\n",
      "| epoch   0 | batch 8500 / 10981 | train_loss 9.75 | train_ppl 17156.829\n",
      "| epoch   0 | batch 9000 / 10981 | train_loss 9.77 | train_ppl 17501.805\n",
      "| epoch   0 | batch 9500 / 10981 | train_loss 9.772 | train_ppl 17532.924\n",
      "| epoch   0 | batch 10000 / 10981 | train_loss 9.768 | train_ppl 17465.709\n",
      "| epoch   1 | batch 500 / 10981 | train_loss 9.688 | train_ppl 16125.41\n",
      "| epoch   1 | batch 1000 / 10981 | train_loss 9.578 | train_ppl 14444.776\n",
      "| epoch   1 | batch 1500 / 10981 | train_loss 9.64 | train_ppl 15360.243\n",
      "| epoch   1 | batch 2000 / 10981 | train_loss 9.638 | train_ppl 15344.099\n",
      "| epoch   1 | batch 2500 / 10981 | train_loss 9.635 | train_ppl 15292.388\n",
      "| epoch   1 | batch 2500 / 10981 | train_loss 9.633 | train_ppl 15259.447 | val_loss 9.745 | val_ppl 17062.178\n",
      "old best ppl 17281.963849636402 new best ppl 17062.178379879413\n",
      "save model... best_model_base_model_ppl_17062.178379879413.model\n",
      "| epoch   1 | batch 3000 / 10981 | train_loss 9.648 | train_ppl 15484.78\n",
      "| epoch   1 | batch 3500 / 10981 | train_loss 9.673 | train_ppl 15888.353\n",
      "| epoch   1 | batch 4000 / 10981 | train_loss 9.657 | train_ppl 15624.211\n",
      "| epoch   1 | batch 4500 / 10981 | train_loss 9.697 | train_ppl 16267.231\n",
      "| epoch   1 | batch 5000 / 10981 | train_loss 9.695 | train_ppl 16243.513\n",
      "| epoch   1 | batch 5500 / 10981 | train_loss 9.765 | train_ppl 17414.702\n",
      "| epoch   1 | batch 6000 / 10981 | train_loss 9.712 | train_ppl 16520.311\n",
      "| epoch   1 | batch 6500 / 10981 | train_loss 9.714 | train_ppl 16547.574\n",
      "| epoch   1 | batch 7000 / 10981 | train_loss 9.724 | train_ppl 16712.21\n",
      "| epoch   1 | batch 7500 / 10981 | train_loss 9.727 | train_ppl 16771.463\n",
      "| epoch   1 | batch 8000 / 10981 | train_loss 9.74 | train_ppl 16977.234\n",
      "| epoch   1 | batch 8500 / 10981 | train_loss 9.745 | train_ppl 17067.095\n",
      "| epoch   1 | batch 9000 / 10981 | train_loss 9.762 | train_ppl 17355.571\n",
      "| epoch   1 | batch 9500 / 10981 | train_loss 9.759 | train_ppl 17314.586\n",
      "| epoch   1 | batch 10000 / 10981 | train_loss 9.762 | train_ppl 17369.019\n",
      "| epoch   2 | batch 500 / 10981 | train_loss 9.654 | train_ppl 15580.411\n",
      "| epoch   2 | batch 1000 / 10981 | train_loss 9.552 | train_ppl 14074.808\n",
      "| epoch   2 | batch 1500 / 10981 | train_loss 9.618 | train_ppl 15033.729\n",
      "| epoch   2 | batch 2000 / 10981 | train_loss 9.614 | train_ppl 14977.882\n",
      "| epoch   2 | batch 2500 / 10981 | train_loss 9.617 | train_ppl 15022.991\n",
      "| epoch   2 | batch 2500 / 10981 | train_loss 9.609 | train_ppl 14898.261 | val_loss 9.732 | val_ppl 16855.346\n",
      "old best ppl 17062.178379879413 new best ppl 16855.345670162922\n",
      "save model... best_model_base_model_ppl_16855.345670162922.model\n",
      "| epoch   2 | batch 3000 / 10981 | train_loss 9.645 | train_ppl 15438.794\n",
      "| epoch   2 | batch 3500 / 10981 | train_loss 9.661 | train_ppl 15697.471\n",
      "| epoch   2 | batch 4000 / 10981 | train_loss 9.646 | train_ppl 15467.214\n",
      "| epoch   2 | batch 4500 / 10981 | train_loss 9.684 | train_ppl 16064.531\n",
      "| epoch   2 | batch 5000 / 10981 | train_loss 9.692 | train_ppl 16184.776\n",
      "| epoch   2 | batch 5500 / 10981 | train_loss 9.708 | train_ppl 16453.385\n",
      "| epoch   2 | batch 6000 / 10981 | train_loss 9.704 | train_ppl 16381.098\n",
      "| epoch   2 | batch 6500 / 10981 | train_loss 9.702 | train_ppl 16345.524\n",
      "| epoch   2 | batch 7000 / 10981 | train_loss 9.718 | train_ppl 16609.404\n",
      "| epoch   2 | batch 7500 / 10981 | train_loss 9.721 | train_ppl 16659.645\n",
      "| epoch   2 | batch 8000 / 10981 | train_loss 9.727 | train_ppl 16758.67\n",
      "| epoch   2 | batch 8500 / 10981 | train_loss 9.733 | train_ppl 16865.855\n",
      "| epoch   2 | batch 9000 / 10981 | train_loss 9.75 | train_ppl 17145.871\n",
      "| epoch   2 | batch 9500 / 10981 | train_loss 9.745 | train_ppl 17076.587\n",
      "| epoch   2 | batch 10000 / 10981 | train_loss 9.742 | train_ppl 17021.12\n",
      "| epoch   3 | batch 500 / 10981 | train_loss 9.57 | train_ppl 14330.478\n",
      "| epoch   3 | batch 1000 / 10981 | train_loss 9.544 | train_ppl 13963.173\n",
      "| epoch   3 | batch 1500 / 10981 | train_loss 9.607 | train_ppl 14862.251\n",
      "| epoch   3 | batch 2000 / 10981 | train_loss 9.602 | train_ppl 14793.763\n",
      "| epoch   3 | batch 2500 / 10981 | train_loss 9.593 | train_ppl 14664.888\n",
      "| epoch   3 | batch 2500 / 10981 | train_loss 9.589 | train_ppl 14607.243 | val_loss 9.723 | val_ppl 16691.293\n",
      "old best ppl 16855.345670162922 new best ppl 16691.292557062658\n",
      "save model... best_model_base_model_ppl_16691.292557062658.model\n",
      "| epoch   3 | batch 3000 / 10981 | train_loss 9.631 | train_ppl 15232.213\n",
      "| epoch   3 | batch 3500 / 10981 | train_loss 9.641 | train_ppl 15386.412\n",
      "| epoch   3 | batch 4000 / 10981 | train_loss 9.628 | train_ppl 15177.477\n",
      "| epoch   3 | batch 4500 / 10981 | train_loss 9.663 | train_ppl 15722.401\n",
      "| epoch   3 | batch 5000 / 10981 | train_loss 9.669 | train_ppl 15813.276\n",
      "| epoch   3 | batch 5500 / 10981 | train_loss 9.699 | train_ppl 16305.44\n",
      "| epoch   3 | batch 6000 / 10981 | train_loss 9.698 | train_ppl 16277.644\n",
      "| epoch   3 | batch 6500 / 10981 | train_loss 9.694 | train_ppl 16221.022\n",
      "| epoch   3 | batch 7000 / 10981 | train_loss 9.715 | train_ppl 16565.288\n",
      "| epoch   3 | batch 7500 / 10981 | train_loss 9.705 | train_ppl 16406.177\n",
      "| epoch   3 | batch 8000 / 10981 | train_loss 9.722 | train_ppl 16687.165\n",
      "| epoch   3 | batch 8500 / 10981 | train_loss 9.724 | train_ppl 16721.621\n",
      "| epoch   3 | batch 9000 / 10981 | train_loss 9.732 | train_ppl 16850.29\n",
      "| epoch   3 | batch 9500 / 10981 | train_loss 9.741 | train_ppl 17003.853\n",
      "| epoch   3 | batch 10000 / 10981 | train_loss 9.738 | train_ppl 16952.367\n",
      "| epoch   4 | batch 500 / 10981 | train_loss 9.639 | train_ppl 15357.559\n",
      "| epoch   4 | batch 1000 / 10981 | train_loss 9.539 | train_ppl 13896.061\n",
      "| epoch   4 | batch 1500 / 10981 | train_loss 9.594 | train_ppl 14678.696\n",
      "| epoch   4 | batch 2000 / 10981 | train_loss 9.599 | train_ppl 14749.085\n",
      "| epoch   4 | batch 2500 / 10981 | train_loss 9.597 | train_ppl 14721.959\n",
      "| epoch   4 | batch 2500 / 10981 | train_loss 9.585 | train_ppl 14547.536 | val_loss 9.73 | val_ppl 16819.707\n",
      "| epoch   4 | batch 3000 / 10981 | train_loss 9.631 | train_ppl 15223.896\n",
      "| epoch   4 | batch 3500 / 10981 | train_loss 9.641 | train_ppl 15384.191\n",
      "| epoch   4 | batch 4000 / 10981 | train_loss 9.626 | train_ppl 15156.467\n",
      "| epoch   4 | batch 4500 / 10981 | train_loss 9.662 | train_ppl 15713.437\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0439f2355d96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mmax_grad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'base_model_ppl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       best_ppl = 26821.121)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-f0b89951877e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ep0, epN, train_iter, dev_iter, optimizer, criterion, max_grad_norm, model_name, best_ppl)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 | batch 500 / 10981 | train_loss 9.716 | train_ppl 16573.915\n",
      "| epoch  14 | batch 1000 / 10981 | train_loss 9.718 | train_ppl 16615.205\n",
      "| epoch  14 | batch 1500 / 10981 | train_loss 9.714 | train_ppl 16546.362\n",
      "| epoch  14 | batch 2000 / 10981 | train_loss 9.706 | train_ppl 16423.484\n",
      "| epoch  14 | batch 2500 / 10981 | train_loss 9.699 | train_ppl 16305.76\n",
      "| epoch  14 | batch 3000 / 10981 | train_loss 9.709 | train_ppl 16473.007\n",
      "| epoch  14 | batch 3500 / 10981 | train_loss 9.719 | train_ppl 16627.063\n",
      "| epoch  14 | batch 4000 / 10981 | train_loss 9.696 | train_ppl 16248.309\n",
      "| epoch  14 | batch 4500 / 10981 | train_loss 9.716 | train_ppl 16576.229\n",
      "| epoch  14 | batch 5000 / 10981 | train_loss 9.734 | train_ppl 16889.702\n",
      "| epoch  14 | batch 5000 / 10981 | train_loss 9.714 | train_ppl 16541.947 | val_loss 9.657 | val_ppl 15633.254\n",
      "| epoch  14 | batch 5500 / 10981 | train_loss 9.736 | train_ppl 16917.136\n",
      "| epoch  14 | batch 6000 / 10981 | train_loss 9.748 | train_ppl 17119.425\n",
      "| epoch  14 | batch 6500 / 10981 | train_loss 9.739 | train_ppl 16970.458\n",
      "| epoch  14 | batch 7000 / 10981 | train_loss 9.752 | train_ppl 17192.51\n",
      "| epoch  14 | batch 7500 / 10981 | train_loss 9.742 | train_ppl 17013.432\n",
      "| epoch  14 | batch 8000 / 10981 | train_loss 9.746 | train_ppl 17084.744\n",
      "| epoch  14 | batch 8500 / 10981 | train_loss 9.722 | train_ppl 16678.861\n",
      "| epoch  14 | batch 9000 / 10981 | train_loss 9.729 | train_ppl 16796.554\n",
      "| epoch  14 | batch 9500 / 10981 | train_loss 9.741 | train_ppl 16994.221\n",
      "| epoch  14 | batch 9999 / 10981 | train_loss 9.727 | train_ppl 16764.413 | val_loss 9.656 | val_ppl 15622.313\n",
      "old best ppl 15624.351 new best ppl 15622.313424147\n",
      "save model... best_model_base_model_ppl_15622.313424147.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BaseModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  14 | batch 10000 / 10981 | train_loss 9.739 | train_ppl 16963.728\n",
      "| epoch  15 | batch 500 / 10981 | train_loss 9.715 | train_ppl 16562.513\n",
      "| epoch  15 | batch 1000 / 10981 | train_loss 9.71 | train_ppl 16482.687\n",
      "| epoch  15 | batch 1500 / 10981 | train_loss 9.714 | train_ppl 16544.264\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
