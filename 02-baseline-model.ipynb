{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import get_iterator, get_dataset\n",
    "from classifiers import theme_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe \n",
    "GLOVE_EMBEDDING = GloVe(name=\"6B\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, review_text_FIELD, theme_FIELD = get_dataset(vectors = \n",
    "                                                                                       GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_iter = get_iterator(train_dataset, batch_size, train=True, shuffle=False, repeat=False)\n",
    "val_iter = get_iterator(val_dataset, batch_size, train=False, shuffle=False, repeat=False)\n",
    "test_iter = get_iterator(test_dataset, batch_size, train=False, shuffle=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train = list(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as usual sad true story ... but great acting | plot\n",
      "anything with jennifer lawrence is worth your time . | other\n",
      "you 'll find them in `` dirty grandpa . | other\n",
      "no direction , worthwhile plot , or acting . | plot\n",
      "although be warned there are some gory scenes . | plot\n",
      "one of the best musical movie for me . | other\n",
      "so disappointed in jake gyllenhall for this one . | other\n",
      "it takes much more than a balance to walk | other\n",
      "that highlights the greatest of a true thriller . | other\n",
      "overall , though , it left me cold . | other\n"
     ]
    }
   ],
   "source": [
    "batch = list_train[600]\n",
    "x = batch.review_text.transpose(1, 0).int()[:10]\n",
    "y = batch.theme.int()\n",
    "\n",
    "for idx in range(x.shape[0]):\n",
    "    #print(x.shape, y.shape)\n",
    "    print(\"{} | {}\".format(' '.join([train_dataset.fields['review_text'].vocab.itos[_] for _ in x[idx]]),\n",
    "         train_dataset.fields['theme'].vocab.itos[y[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#review_text_FIELD.vocab.vectors.shape, len(review_text_FIELD.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'other', 'plot', 'acting', 'effect', 'production']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_FIELD.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = review_text_FIELD.vocab.vectors.shape[0]\n",
    "label_size = len(theme_FIELD.vocab) - 1\n",
    "emb_dim = review_text_FIELD.vocab.vectors.shape[1]\n",
    "vectors = train_dataset.fields[\"review_text\"].vocab.vectors\n",
    "hidden_dim = 500\n",
    "layers = 2\n",
    "dropout = .2\n",
    "\n",
    "label_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, \n",
    "                 ninp = vocab_size, \n",
    "                 linp = label_size, \n",
    "                 emb_dim = emb_dim, \n",
    "                 emb_lab = 20,\n",
    "                 nhid = hidden_dim, \n",
    "                 nout = vocab_size, \n",
    "                 nlayers = layers, \n",
    "                 dropout = dropout, \n",
    "                 vectors = vectors,\n",
    "                 pretrained = False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ninp = ninp\n",
    "        self.linp = linp\n",
    "        self.emb_dim = emb_dim\n",
    "        self.emb_lab = emb_lab\n",
    "        self.nhid = nhid\n",
    "        self.nout = nout\n",
    "        self.nlayers = nlayers\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        self.word_embedding = nn.Embedding(ninp, emb_dim)\n",
    "        self.label_embedding = nn.Embedding(linp, emb_lab)\n",
    "        \n",
    "        self.rnn = nn.LSTM(emb_dim + emb_lab, nhid, nlayers, dropout=dropout)\n",
    "        self.rnn.flatten_parameters()\n",
    "        self.decoder = nn.Linear(nhid, nout)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "        if pretrained:\n",
    "            self.encoder.weight.data = vectors\n",
    "            \n",
    "    def init_weights(self):\n",
    "        initrange = .1\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, reviews, labels, hidden):\n",
    "        R = self.word_embedding(reviews)\n",
    "        L = self.label_embedding(labels)\n",
    "        L = torch.cat([L.unsqueeze(0)]*R.shape[0])\n",
    "        X = torch.cat([R, L], -1)\n",
    "        \n",
    "        X, hidden = self.rnn(X, hidden)\n",
    "        X = X.view(X.size(0)*X.size(1), X.size(2))\n",
    "        \n",
    "        X = self.decoder(X)\n",
    "        log_probs = self.softmax(X)\n",
    "        return log_probs, hidden\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaseModel().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement PPL\n",
    "learning_rate = 0.001\n",
    "criterion = nn.NLLLoss(reduction='sum', \n",
    "                       ignore_index=train_dataset.fields[\"review_text\"].vocab.stoi['<pad>']).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(data_source):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    total_loss_e = 0\n",
    "    total_number_of_words = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_source):\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            hidden = None\n",
    "            if batch.shape[0] > 1:\n",
    "                data, targets = batch[:-1,:], batch[1:,:]\n",
    "                number_of_words = data.shape[0]*data.shape[1]\n",
    "                \n",
    "                output, hidden = model(data, labels, hidden)\n",
    "                output_flat = output.contiguous().view(-1, vocab_size)\n",
    "\n",
    "                total_loss_e += criterion(output_flat, targets.contiguous().view(-1)).data.float()\n",
    "                total_number_of_words += number_of_words\n",
    "                hidden = repackage_hidden(hidden)\n",
    "            \n",
    "    return total_loss_e.item() / total_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(ep0, epN, train_iter, dev_iter, optimizer, criterion, \n",
    "          max_grad_norm, model_name, best_ppl = float('inf')):\n",
    "    \n",
    "    best_ppl = best_ppl\n",
    "    \n",
    "    len_train_iter = len(train_iter)\n",
    "    for epoch in range(ep0, epN):\n",
    "        total_loss_e = 0\n",
    "        total_number_of_words = 0 \n",
    "        \n",
    "        for i, batch in enumerate(train_iter):\n",
    "\n",
    "            model.zero_grad()\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            hidden = None\n",
    "            if batch.shape[0] > 1:\n",
    "                model.train()\n",
    "\n",
    "\n",
    "                data, targets = batch[:-1,:], batch[1:,:]\n",
    "                number_of_words = data.shape[0]*data.shape[1]\n",
    "                \n",
    "                output, hidden = model(data, labels, hidden)\n",
    "                output_flat = output.contiguous().view(-1, vocab_size)\n",
    "\n",
    "                epoch_loss = criterion(output_flat, targets.contiguous().view(-1))\n",
    "                total_loss_e += epoch_loss.data.float()\n",
    "                total_number_of_words += number_of_words\n",
    "                hidden = repackage_hidden(hidden)\n",
    "            \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(),max_grad_norm)\n",
    "                optimizer.zero_grad()\n",
    "                epoch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                cur_loss = total_loss_e.item() / total_number_of_words\n",
    "                tr_ppl_print = np.exp(cur_loss)\n",
    "                val_loss_eval = evaluate(dev_iter)\n",
    "                val_ppl_print = np.exp(val_loss_eval)\n",
    "\n",
    "                print(\"| epoch {:3d} | batch {} / {} | train_loss {} | train_ppl {} | val_loss {} | val_ppl {}\".format(\n",
    "                        epoch, i, len_train_iter, \n",
    "                        np.round(cur_loss, 3), np.round(tr_ppl_print, 3), \n",
    "                        np.round(val_loss_eval, 3), np.round(val_ppl_print, 3)))\n",
    "\n",
    "                if val_ppl_print < best_ppl :\n",
    "                    print('old best ppl {} new best ppl {}'.format(best_ppl, val_ppl_print))\n",
    "                    best_ppl = val_ppl_print\n",
    "                    best_model_name = 'best_model_{}_{}.model'.format(model_name, best_ppl)\n",
    "                    print('save model...', best_model_name)\n",
    "                    with open(best_model_name, 'wb') as file:\n",
    "                        torch.save(model, file) \n",
    "            else:\n",
    "                print(i, batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([0, 32])\n",
      "1 torch.Size([0, 32])\n",
      "2 torch.Size([0, 32])\n",
      "3 torch.Size([0, 32])\n",
      "4 torch.Size([0, 32])\n",
      "5 torch.Size([0, 32])\n",
      "6 torch.Size([0, 32])\n",
      "7 torch.Size([0, 32])\n",
      "8 torch.Size([0, 32])\n",
      "9 torch.Size([0, 32])\n",
      "10 torch.Size([0, 32])\n",
      "11 torch.Size([0, 32])\n",
      "12 torch.Size([0, 32])\n",
      "13 torch.Size([0, 32])\n",
      "14 torch.Size([0, 32])\n",
      "15 torch.Size([0, 32])\n",
      "16 torch.Size([0, 32])\n",
      "17 torch.Size([1, 32])\n",
      "18 torch.Size([1, 32])\n",
      "19 torch.Size([1, 32])\n",
      "20 torch.Size([1, 32])\n",
      "21 torch.Size([1, 32])\n",
      "22 torch.Size([1, 32])\n",
      "23 torch.Size([1, 32])\n",
      "24 torch.Size([1, 32])\n",
      "25 torch.Size([1, 32])\n",
      "26 torch.Size([1, 32])\n",
      "27 torch.Size([1, 32])\n",
      "28 torch.Size([1, 32])\n",
      "29 torch.Size([1, 32])\n",
      "30 torch.Size([1, 32])\n",
      "31 torch.Size([1, 32])\n",
      "32 torch.Size([1, 32])\n",
      "33 torch.Size([1, 32])\n",
      "34 torch.Size([1, 32])\n",
      "35 torch.Size([1, 32])\n",
      "36 torch.Size([1, 32])\n",
      "37 torch.Size([1, 32])\n",
      "38 torch.Size([1, 32])\n",
      "39 torch.Size([1, 32])\n",
      "40 torch.Size([1, 32])\n",
      "41 torch.Size([1, 32])\n",
      "42 torch.Size([1, 32])\n",
      "43 torch.Size([1, 32])\n",
      "44 torch.Size([1, 32])\n",
      "45 torch.Size([1, 32])\n",
      "46 torch.Size([1, 32])\n",
      "47 torch.Size([1, 32])\n",
      "48 torch.Size([1, 32])\n",
      "49 torch.Size([1, 32])\n",
      "50 torch.Size([1, 32])\n",
      "51 torch.Size([1, 32])\n",
      "52 torch.Size([1, 32])\n",
      "53 torch.Size([1, 32])\n",
      "54 torch.Size([1, 32])\n",
      "55 torch.Size([1, 32])\n",
      "56 torch.Size([1, 32])\n",
      "57 torch.Size([1, 32])\n",
      "58 torch.Size([1, 32])\n",
      "59 torch.Size([1, 32])\n",
      "60 torch.Size([1, 32])\n",
      "61 torch.Size([1, 32])\n",
      "62 torch.Size([1, 32])\n",
      "63 torch.Size([1, 32])\n",
      "64 torch.Size([1, 32])\n",
      "65 torch.Size([1, 32])\n",
      "66 torch.Size([1, 32])\n",
      "67 torch.Size([1, 32])\n",
      "68 torch.Size([1, 32])\n",
      "69 torch.Size([1, 32])\n",
      "70 torch.Size([1, 32])\n",
      "71 torch.Size([1, 32])\n",
      "72 torch.Size([1, 32])\n",
      "73 torch.Size([1, 32])\n",
      "74 torch.Size([1, 32])\n",
      "75 torch.Size([1, 32])\n",
      "76 torch.Size([1, 32])\n",
      "77 torch.Size([1, 32])\n",
      "78 torch.Size([1, 32])\n",
      "79 torch.Size([1, 32])\n",
      "80 torch.Size([1, 32])\n",
      "81 torch.Size([1, 32])\n",
      "82 torch.Size([1, 32])\n",
      "83 torch.Size([1, 32])\n",
      "84 torch.Size([1, 32])\n",
      "85 torch.Size([1, 32])\n",
      "86 torch.Size([1, 32])\n",
      "87 torch.Size([1, 32])\n",
      "88 torch.Size([1, 32])\n",
      "89 torch.Size([1, 32])\n",
      "90 torch.Size([1, 32])\n",
      "91 torch.Size([1, 32])\n",
      "92 torch.Size([1, 32])\n",
      "93 torch.Size([1, 32])\n",
      "94 torch.Size([1, 32])\n",
      "95 torch.Size([1, 32])\n",
      "96 torch.Size([1, 32])\n",
      "97 torch.Size([1, 32])\n",
      "98 torch.Size([1, 32])\n",
      "99 torch.Size([1, 32])\n",
      "100 torch.Size([1, 32])\n",
      "101 torch.Size([1, 32])\n",
      "102 torch.Size([1, 32])\n",
      "103 torch.Size([1, 32])\n",
      "104 torch.Size([1, 32])\n",
      "105 torch.Size([1, 32])\n",
      "106 torch.Size([1, 32])\n",
      "107 torch.Size([1, 32])\n",
      "108 torch.Size([1, 32])\n",
      "109 torch.Size([1, 32])\n",
      "110 torch.Size([1, 32])\n",
      "111 torch.Size([1, 32])\n",
      "112 torch.Size([1, 32])\n",
      "113 torch.Size([1, 32])\n",
      "114 torch.Size([1, 32])\n",
      "115 torch.Size([1, 32])\n",
      "116 torch.Size([1, 32])\n",
      "117 torch.Size([1, 32])\n",
      "118 torch.Size([1, 32])\n",
      "119 torch.Size([1, 32])\n",
      "120 torch.Size([1, 32])\n",
      "121 torch.Size([1, 32])\n",
      "122 torch.Size([1, 32])\n",
      "123 torch.Size([1, 32])\n",
      "124 torch.Size([1, 32])\n",
      "125 torch.Size([1, 32])\n",
      "126 torch.Size([1, 32])\n",
      "127 torch.Size([1, 32])\n",
      "128 torch.Size([1, 32])\n",
      "129 torch.Size([1, 32])\n",
      "| epoch   0 | batch 130 / 21962 | train_loss 9.099 | train_ppl 8941.932 | val_loss 10.211 | val_ppl 27197.163\n",
      "old best ppl inf new best ppl 27197.163098554924\n",
      "save model... best_model_base_model_ppl_27197.163098554924.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BaseModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | batch 131 / 21962 | train_loss 9.6 | train_ppl 14762.478 | val_loss 10.192 | val_ppl 26679.652\n",
      "old best ppl 27197.163098554924 new best ppl 26679.652228685365\n",
      "save model... best_model_base_model_ppl_26679.652228685365.model\n",
      "| epoch   0 | batch 132 / 21962 | train_loss 9.756 | train_ppl 17262.839 | val_loss 10.168 | val_ppl 26060.512\n",
      "old best ppl 26679.652228685365 new best ppl 26060.512268175233\n",
      "save model... best_model_base_model_ppl_26060.512268175233.model\n",
      "| epoch   0 | batch 133 / 21962 | train_loss 9.801 | train_ppl 18045.464 | val_loss 10.14 | val_ppl 25343.971\n",
      "old best ppl 26060.512268175233 new best ppl 25343.971109642982\n",
      "save model... best_model_base_model_ppl_25343.971109642982.model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-cd57e480fe1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mmax_grad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'base_model_ppl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m       best_ppl = float('inf'))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-467d2c421afd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(ep0, epN, train_iter, dev_iter, optimizer, criterion, max_grad_norm, model_name, best_ppl)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mcur_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss_e\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtotal_number_of_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mtr_ppl_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mval_loss_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                 \u001b[0mval_ppl_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-7e996768e5f8>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(data_source)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtotal_number_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheme\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreview_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/iterator.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                         \u001b[0mminibatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/batch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, dataset, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                     \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, batch, device)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \"\"\"\n\u001b[1;32m    200\u001b[0m         \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumericalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchtext/data/field.py\u001b[0m in \u001b[0;36mnumericalize\u001b[0;34m(self, arr, device)\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_first\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(ep0 = 0,\n",
    "      epN = 1,\n",
    "      train_iter = train_iter,\n",
    "      dev_iter = val_iter,\n",
    "      optimizer = optimizer,\n",
    "      criterion = criterion,\n",
    "      max_grad_norm = 5,\n",
    "      model_name = 'base_model_ppl',\n",
    "      best_ppl = float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add <sos> and <eos>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30002"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30083.068177308916"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(evaluate(val_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
