{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a baseline trained only with PPL, which has already converged and will be used as our baseline.\n",
    "# they do teacher forcing all the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import get_iterator, get_dataset\n",
    "from classifiers import theme_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.vocab import GloVe \n",
    "GLOVE_EMBEDDING = GloVe(name=\"6B\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, review_text_FIELD, theme_FIELD = get_dataset(vectors = GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_iter = get_iterator(train_dataset, batch_size, train=True, shuffle=True, repeat=False)\n",
    "val_iter = get_iterator(val_dataset, batch_size, train=False, shuffle=True, repeat=False)\n",
    "test_iter = get_iterator(test_dataset, batch_size, train=False, shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_list = list(val_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> awesome sauce <eos> | other\n",
      "<sos> totally recommend <eos> | other\n",
      "<sos> <unk> . <eos> | other\n",
      "<sos> truly amazing <eos> | other\n",
      "<sos> talky . <eos> | other\n",
      "<sos> must see <eos> | other\n",
      "<sos> 3.5 5 <eos> | other\n",
      "<sos> 5 stars <eos> | other\n",
      "<sos> movie ? <eos> | other\n",
      "<sos> brutal . <eos> | other\n"
     ]
    }
   ],
   "source": [
    "batch = val_list[50]\n",
    "x = batch.review_text.transpose(1, 0).int()[:10]\n",
    "y = batch.theme.int()\n",
    "\n",
    "for idx in range(x.shape[0]):\n",
    "    #print(x.shape, y.shape)\n",
    "    print(\"{} | {}\".format(' '.join([train_dataset.fields['review_text'].vocab.itos[_] for _ in x[idx]]),\n",
    "         train_dataset.fields['theme'].vocab.itos[y[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'other', 'plot', 'acting', 'effect', 'production']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theme_FIELD.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12304, 5, 300, torch.Size([12304, 300]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = review_text_FIELD.vocab.vectors.shape[0]\n",
    "label_size = len(theme_FIELD.vocab) - 1\n",
    "emb_dim = review_text_FIELD.vocab.vectors.shape[1]\n",
    "vectors = train_dataset.fields[\"review_text\"].vocab.vectors\n",
    "hidden_dim = 1024\n",
    "layers = 2\n",
    "dropout = .5\n",
    "\n",
    "vocab_size, label_size, emb_dim, vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model import BaseModel, repackage_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EOS_token = review_text_FIELD.vocab.stoi['<eos>']\n",
    "EOS_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(model, data, labels, i):\n",
    "    \n",
    "    split_tf = data.shape[0] - (i % data.shape[0])\n",
    "    #print(split_tf)\n",
    "    \n",
    "    seq_len = data.shape[0]\n",
    "    data_tf = data[:split_tf,:]\n",
    "    data_nf = data[split_tf:,:]\n",
    "\n",
    "    output_flat = None\n",
    "    hidden = None\n",
    "    \n",
    "    if split_tf > 0:\n",
    "\n",
    "        data = data_tf\n",
    "        output_tf, hidden = model(data, labels, hidden)\n",
    "        repackage_hidden(hidden)\n",
    "        output_flat = output_tf.contiguous().view(-1, vocab_size)\n",
    "\n",
    "    if split_tf < seq_len:\n",
    "\n",
    "        data = data_nf\n",
    "        shape = tuple((*data_nf.shape, vocab_size))\n",
    "        output_nf = torch.zeros(shape).cuda()\n",
    "        hidden_i = None\n",
    "        data_i = data[0,:]    \n",
    "\n",
    "        for di in range(data_nf.shape[0]):\n",
    "            params = data_i.unsqueeze(0), labels, hidden_i\n",
    "            output_i, hidden_i = model(*params)\n",
    "            hidden_i = repackage_hidden(hidden_i)\n",
    "            topv, topi = output_i.topk(1)\n",
    "            data_i = topi.squeeze().detach()\n",
    "            output_nf[di,:] = output_i\n",
    "\n",
    "        temp_output_flat = output_nf.contiguous().view(-1, vocab_size)\n",
    "        if output_flat is None:\n",
    "            output_flat = temp_output_flat\n",
    "        else:\n",
    "            output_flat = torch.cat([output_flat, temp_output_flat], 0)\n",
    "            \n",
    "    return output_flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_source, criterion, teacher_forcing = False):\n",
    "    model.eval()\n",
    "    total_loss_e = 0\n",
    "    total_number_of_words = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_source):\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            \n",
    "            if batch.shape[0] > 3:\n",
    "                data, targets = batch[1:-1,:], batch[2:,:]\n",
    "                target_flat = targets.contiguous().view(-1)\n",
    "                \n",
    "                tf = i if not teacher_forcing else 0\n",
    "                output_flat = forward_pass(model, data, labels, tf)\n",
    "                \n",
    "                batch_loss = criterion(output_flat, target_flat).detach().item()\n",
    "                number_of_words = data.shape[0] * data.shape[1]\n",
    "                total_loss_e += batch_loss * number_of_words\n",
    "                total_number_of_words += number_of_words\n",
    "            \n",
    "    return total_loss_e / total_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, ep0, epN, train_iter, dev_iter, optimizer, criterion, \n",
    "          max_grad_norm, model_name, best_ppl = float('inf'), teacher_forcing = False):\n",
    "    \n",
    "    best_ppl = best_ppl\n",
    "    \n",
    "    len_train_iter = len(train_iter)\n",
    "    for epoch in range(ep0, epN):\n",
    "        model.train()\n",
    "        total_loss_e = 0\n",
    "        total_number_of_words = 0 \n",
    "        \n",
    "        for i, batch in enumerate(train_iter):\n",
    "\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            hidden = None\n",
    "            \n",
    "            if batch.shape[0] > 3:\n",
    "                data, targets = batch[1:-1,:], batch[2:,:]\n",
    "                \n",
    "                tf = i if not teacher_forcing else 0\n",
    "                output_flat = forward_pass(model, data, labels, tf)\n",
    "                \n",
    "                target_flat = targets.contiguous().view(-1)\n",
    "                batch_loss = criterion(output_flat, target_flat)\n",
    "                \n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "                optimizer.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                number_of_words = data.shape[0] * data.shape[1]\n",
    "                total_loss_e += batch_loss.detach().item() * number_of_words\n",
    "                total_number_of_words += number_of_words\n",
    "            \n",
    "                \n",
    "                if i % 500 == 0:\n",
    "                    cur_loss = batch_loss.detach().item() \n",
    "                    tr_ppl_print = np.exp(cur_loss)\n",
    "                    print(\"| epoch {:3d} | batch {} / {} | train_loss {} | train_ppl {}\".format(\n",
    "                            epoch, i, len_train_iter, \n",
    "                            np.round(cur_loss, 3), np.round(tr_ppl_print, 3)))\n",
    "\n",
    "                \n",
    "                if i % 4999 == 1: #len_train_iter - 1:\n",
    "                    cur_loss = batch_loss.detach().item()\n",
    "                    tr_ppl_print = np.exp(cur_loss)\n",
    "                    gc.collect()\n",
    "                    val_loss_eval = evaluate(model, dev_iter, criterion)\n",
    "                    val_ppl_print = np.exp(val_loss_eval)\n",
    "                    \n",
    "                    template = \"| epoch {:3d} | batch {} / {} | train_loss {} | train_ppl {} | val_loss {} | val_ppl {}\"\n",
    "                    print(template.format(\n",
    "                            epoch, i, len_train_iter, \n",
    "                            np.round(cur_loss, 3), np.round(tr_ppl_print, 3), \n",
    "                            np.round(val_loss_eval, 3), np.round(val_ppl_print, 3)))\n",
    "\n",
    "                    if val_ppl_print < best_ppl :\n",
    "                        print('old best ppl {} new best ppl {}'.format(best_ppl, val_ppl_print))\n",
    "                        best_ppl = val_ppl_print\n",
    "                        best_model_name = '{}_{}.model'.format(model_name, best_ppl)\n",
    "                        print('save model...', best_model_name)\n",
    "                        with open(best_model_name, 'wb') as file:\n",
    "                            torch.save(model, file) \n",
    "\n",
    "                    gc.collect()\n",
    "                    model.train()\n",
    "                    \n",
    "                if i == 40000: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./no-teacher-forcing/model_ppl_188.3817233517709.model', 'rb') as file:\n",
    "    model = torch.load(file)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (word_embedding): Embedding(12304, 300)\n",
       "  (label_embedding): Embedding(5, 20)\n",
       "  (rnn): LSTM(320, 1024, num_layers=2, dropout=0.5)\n",
       "  (decoder): Linear(in_features=1024, out_features=12304, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss(reduction='mean',\n",
    "                       ignore_index=train_dataset.fields[\"review_text\"].vocab.stoi['<pad>']).cuda()\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)#, betas=(.9999, .9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate(model, val_iter, criterion, teacher_forcing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200.43172567537505"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(5.300473668434095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | batch 500 / 35138 | train_loss 3.841 | train_ppl 46.573\n",
      "| epoch   3 | batch 1000 / 35138 | train_loss 3.067 | train_ppl 21.467\n",
      "| epoch   3 | batch 1500 / 35138 | train_loss 3.672 | train_ppl 39.318\n",
      "| epoch   3 | batch 2000 / 35138 | train_loss 4.235 | train_ppl 69.031\n",
      "| epoch   3 | batch 2500 / 35138 | train_loss 4.057 | train_ppl 57.773\n",
      "| epoch   3 | batch 3000 / 35138 | train_loss 4.128 | train_ppl 62.074\n",
      "| epoch   3 | batch 3500 / 35138 | train_loss 4.615 | train_ppl 100.944\n",
      "| epoch   3 | batch 4000 / 35138 | train_loss 4.548 | train_ppl 94.432\n",
      "| epoch   3 | batch 4500 / 35138 | train_loss 4.481 | train_ppl 88.351\n",
      "| epoch   3 | batch 5000 / 35138 | train_loss 4.839 | train_ppl 126.329\n",
      "| epoch   3 | batch 5000 / 35138 | train_loss 4.839 | train_ppl 126.329 | val_loss 5.238 | val_ppl 188.208\n",
      "old best ppl 188.382 new best ppl 188.20771813579665\n",
      "save model... no-teacher-forcing/model_ppl_188.20771813579665.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BaseModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   3 | batch 5500 / 35138 | train_loss 5.043 | train_ppl 154.944\n",
      "| epoch   3 | batch 6000 / 35138 | train_loss 4.176 | train_ppl 65.094\n",
      "| epoch   3 | batch 6500 / 35138 | train_loss 4.643 | train_ppl 103.83\n",
      "| epoch   3 | batch 7000 / 35138 | train_loss 5.17 | train_ppl 175.931\n",
      "| epoch   3 | batch 7500 / 35138 | train_loss 4.384 | train_ppl 80.171\n",
      "| epoch   3 | batch 8000 / 35138 | train_loss 5.119 | train_ppl 167.205\n",
      "| epoch   3 | batch 8500 / 35138 | train_loss 3.956 | train_ppl 52.264\n",
      "| epoch   3 | batch 9000 / 35138 | train_loss 4.272 | train_ppl 71.662\n",
      "| epoch   3 | batch 9500 / 35138 | train_loss 5.216 | train_ppl 184.212\n"
     ]
    }
   ],
   "source": [
    "train(model,\n",
    "      ep0 = 3,\n",
    "      epN = 4,\n",
    "      train_iter = train_iter,\n",
    "      dev_iter = val_iter,\n",
    "      optimizer = optimizer,\n",
    "      criterion = criterion,\n",
    "      max_grad_norm = 10,\n",
    "      model_name = 'no-teacher-forcing/model_ppl',\n",
    "      best_ppl = 188.382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | batch 500 / 35138 | train_loss 1.877 | train_ppl 6.534\n",
      "| epoch   2 | batch 1000 / 35138 | train_loss 1.729 | train_ppl 5.632\n",
      "| epoch   2 | batch 1500 / 35138 | train_loss 1.975 | train_ppl 7.205\n",
      "| epoch   2 | batch 2000 / 35138 | train_loss 3.559 | train_ppl 35.135\n",
      "| epoch   2 | batch 2500 / 35138 | train_loss 3.516 | train_ppl 33.64\n",
      "| epoch   2 | batch 3000 / 35138 | train_loss 3.418 | train_ppl 30.512\n",
      "| epoch   2 | batch 3500 / 35138 | train_loss 3.915 | train_ppl 50.149\n",
      "| epoch   2 | batch 4000 / 35138 | train_loss 4.437 | train_ppl 84.486\n",
      "| epoch   2 | batch 4500 / 35138 | train_loss 3.952 | train_ppl 52.045\n",
      "| epoch   2 | batch 5000 / 35138 | train_loss 4.573 | train_ppl 96.801\n",
      "| epoch   2 | batch 5000 / 35138 | train_loss 4.573 | train_ppl 96.801 | val_loss 5.813 | val_ppl 334.701\n",
      "| epoch   2 | batch 5500 / 35138 | train_loss 4.864 | train_ppl 129.486\n",
      "| epoch   2 | batch 6000 / 35138 | train_loss 3.992 | train_ppl 54.139\n",
      "| epoch   2 | batch 6500 / 35138 | train_loss 4.565 | train_ppl 96.025\n",
      "| epoch   2 | batch 7000 / 35138 | train_loss 5.13 | train_ppl 168.967\n",
      "| epoch   2 | batch 7500 / 35138 | train_loss 4.411 | train_ppl 82.321\n",
      "| epoch   2 | batch 8000 / 35138 | train_loss 5.109 | train_ppl 165.521\n",
      "| epoch   2 | batch 8500 / 35138 | train_loss 3.957 | train_ppl 52.28\n",
      "| epoch   2 | batch 9000 / 35138 | train_loss 4.274 | train_ppl 71.774\n",
      "| epoch   2 | batch 9500 / 35138 | train_loss 5.285 | train_ppl 197.433\n",
      "| epoch   2 | batch 9999 / 35138 | train_loss 3.892 | train_ppl 49.03 | val_loss 5.8 | val_ppl 330.287\n",
      "| epoch   2 | batch 10000 / 35138 | train_loss 4.235 | train_ppl 69.068\n",
      "| epoch   2 | batch 10500 / 35138 | train_loss 5.164 | train_ppl 174.917\n",
      "| epoch   2 | batch 11000 / 35138 | train_loss 5.26 | train_ppl 192.544\n",
      "| epoch   2 | batch 11500 / 35138 | train_loss 4.285 | train_ppl 72.604\n",
      "| epoch   2 | batch 12000 / 35138 | train_loss 3.642 | train_ppl 38.161\n",
      "| epoch   2 | batch 12500 / 35138 | train_loss 4.652 | train_ppl 104.831\n",
      "| epoch   2 | batch 13000 / 35138 | train_loss 5.1 | train_ppl 163.946\n",
      "| epoch   2 | batch 13500 / 35138 | train_loss 4.998 | train_ppl 148.189\n",
      "| epoch   2 | batch 14000 / 35138 | train_loss 4.306 | train_ppl 74.164\n",
      "| epoch   2 | batch 14500 / 35138 | train_loss 5.709 | train_ppl 301.493\n",
      "| epoch   2 | batch 14998 / 35138 | train_loss 6.137 | train_ppl 462.646 | val_loss 5.408 | val_ppl 223.24\n",
      "| epoch   2 | batch 15000 / 35138 | train_loss 4.085 | train_ppl 59.428\n",
      "| epoch   2 | batch 15500 / 35138 | train_loss 5.709 | train_ppl 301.525\n",
      "| epoch   2 | batch 16000 / 35138 | train_loss 4.115 | train_ppl 61.227\n",
      "| epoch   2 | batch 16500 / 35138 | train_loss 5.367 | train_ppl 214.189\n",
      "| epoch   2 | batch 17000 / 35138 | train_loss 3.943 | train_ppl 51.554\n",
      "| epoch   2 | batch 17500 / 35138 | train_loss 5.153 | train_ppl 172.971\n",
      "| epoch   2 | batch 18000 / 35138 | train_loss 4.492 | train_ppl 89.28\n",
      "| epoch   2 | batch 18500 / 35138 | train_loss 5.613 | train_ppl 273.893\n",
      "| epoch   2 | batch 19000 / 35138 | train_loss 4.008 | train_ppl 55.031\n",
      "| epoch   2 | batch 19500 / 35138 | train_loss 4.928 | train_ppl 138.107\n",
      "| epoch   2 | batch 19997 / 35138 | train_loss 5.933 | train_ppl 377.319 | val_loss 5.238 | val_ppl 188.382\n",
      "old best ppl 200.43172567537505 new best ppl 188.3817233517709\n",
      "save model... no-teacher-forcing/model_ppl_188.3817233517709.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BaseModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   2 | batch 20000 / 35138 | train_loss 4.591 | train_ppl 98.579\n",
      "| epoch   2 | batch 20500 / 35138 | train_loss 4.357 | train_ppl 77.992\n",
      "| epoch   2 | batch 21000 / 35138 | train_loss 4.41 | train_ppl 82.289\n",
      "| epoch   2 | batch 21500 / 35138 | train_loss 6.286 | train_ppl 537.266\n",
      "| epoch   2 | batch 22000 / 35138 | train_loss 4.862 | train_ppl 129.255\n",
      "| epoch   2 | batch 22500 / 35138 | train_loss 5.501 | train_ppl 244.908\n",
      "| epoch   2 | batch 23000 / 35138 | train_loss 4.533 | train_ppl 93.076\n",
      "| epoch   2 | batch 23500 / 35138 | train_loss 4.756 | train_ppl 116.317\n",
      "| epoch   2 | batch 24000 / 35138 | train_loss 4.855 | train_ppl 128.354\n",
      "| epoch   2 | batch 24500 / 35138 | train_loss 4.63 | train_ppl 102.533\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-db314d47a16a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mmax_grad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'no-teacher-forcing/model_ppl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       best_ppl = 200.43172567537505)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-a16995e8b8f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ep0, epN, train_iter, dev_iter, optimizer, criterion, max_grad_norm, model_name, best_ppl, teacher_forcing)\u001b[0m\n\u001b[1;32m     47\u001b[0m                     \u001b[0mtr_ppl_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                     \u001b[0mval_loss_eval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                     \u001b[0mval_ppl_print\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-05a2b4a6a42e>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_source, criterion, teacher_forcing)\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0moutput_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0mnumber_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mtotal_loss_e\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumber_of_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,\n",
    "      ep0 = 1,\n",
    "      epN = 2,\n",
    "      train_iter = train_iter,\n",
    "      dev_iter = val_iter,\n",
    "      optimizer = optimizer,\n",
    "      criterion = criterion,\n",
    "      max_grad_norm = 10,\n",
    "      model_name = 'no-teacher-forcing/model_ppl',\n",
    "      best_ppl = 200.43172567537505)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | batch 500 / 35138 | train_loss 2.503 | train_ppl 12.218\n",
      "| epoch   0 | batch 1000 / 35138 | train_loss 2.95 | train_ppl 19.103\n",
      "| epoch   0 | batch 1500 / 35138 | train_loss 2.853 | train_ppl 17.337\n",
      "| epoch   0 | batch 2000 / 35138 | train_loss 3.617 | train_ppl 37.235\n",
      "| epoch   0 | batch 2500 / 35138 | train_loss 3.536 | train_ppl 34.321\n",
      "| epoch   0 | batch 3000 / 35138 | train_loss 3.504 | train_ppl 33.265\n",
      "| epoch   0 | batch 3500 / 35138 | train_loss 4.776 | train_ppl 118.588\n",
      "| epoch   0 | batch 4000 / 35138 | train_loss 5.511 | train_ppl 247.355\n",
      "| epoch   0 | batch 4500 / 35138 | train_loss 4.247 | train_ppl 69.926\n",
      "| epoch   0 | batch 5000 / 35138 | train_loss 4.605 | train_ppl 100.01\n",
      "| epoch   0 | batch 5000 / 35138 | train_loss 4.605 | train_ppl 100.01 | val_loss 6.354 | val_ppl 574.88\n",
      "old best ppl inf new best ppl 574.8795707969175\n",
      "save model... no-teacher-forcing/model_ppl_574.8795707969175.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BaseModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | batch 5500 / 35138 | train_loss 6.005 | train_ppl 405.364\n",
      "| epoch   0 | batch 6000 / 35138 | train_loss 3.74 | train_ppl 42.103\n",
      "| epoch   0 | batch 6500 / 35138 | train_loss 4.746 | train_ppl 115.148\n",
      "| epoch   0 | batch 7000 / 35138 | train_loss 5.954 | train_ppl 385.253\n",
      "| epoch   0 | batch 7500 / 35138 | train_loss 4.211 | train_ppl 67.427\n",
      "| epoch   0 | batch 8000 / 35138 | train_loss 6.44 | train_ppl 626.429\n",
      "| epoch   0 | batch 8500 / 35138 | train_loss 4.041 | train_ppl 56.855\n",
      "| epoch   0 | batch 9000 / 35138 | train_loss 4.318 | train_ppl 75.062\n",
      "| epoch   0 | batch 9500 / 35138 | train_loss 5.659 | train_ppl 286.859\n",
      "| epoch   0 | batch 9999 / 35138 | train_loss 4.001 | train_ppl 54.663 | val_loss 5.534 | val_ppl 253.173\n",
      "old best ppl 574.8795707969175 new best ppl 253.172912038308\n",
      "save model... no-teacher-forcing/model_ppl_253.172912038308.model\n",
      "| epoch   0 | batch 10000 / 35138 | train_loss 4.209 | train_ppl 67.273\n",
      "| epoch   0 | batch 10500 / 35138 | train_loss 5.15 | train_ppl 172.5\n",
      "| epoch   0 | batch 11000 / 35138 | train_loss 5.36 | train_ppl 212.812\n",
      "| epoch   0 | batch 11500 / 35138 | train_loss 4.474 | train_ppl 87.7\n",
      "| epoch   0 | batch 12000 / 35138 | train_loss 3.912 | train_ppl 49.994\n",
      "| epoch   0 | batch 12500 / 35138 | train_loss 4.857 | train_ppl 128.589\n",
      "| epoch   0 | batch 13000 / 35138 | train_loss 5.293 | train_ppl 198.84\n",
      "| epoch   0 | batch 13500 / 35138 | train_loss 5.062 | train_ppl 157.97\n",
      "| epoch   0 | batch 14000 / 35138 | train_loss 4.525 | train_ppl 92.323\n",
      "| epoch   0 | batch 14500 / 35138 | train_loss 5.89 | train_ppl 361.355\n",
      "| epoch   0 | batch 14998 / 35138 | train_loss 6.245 | train_ppl 515.681 | val_loss 5.447 | val_ppl 232.102\n",
      "old best ppl 253.172912038308 new best ppl 232.10221731269863\n",
      "save model... no-teacher-forcing/model_ppl_232.10221731269863.model\n",
      "| epoch   0 | batch 15000 / 35138 | train_loss 4.498 | train_ppl 89.825\n",
      "| epoch   0 | batch 15500 / 35138 | train_loss 5.97 | train_ppl 391.558\n",
      "| epoch   0 | batch 16000 / 35138 | train_loss 4.471 | train_ppl 87.424\n",
      "| epoch   0 | batch 16500 / 35138 | train_loss 5.483 | train_ppl 240.517\n",
      "| epoch   0 | batch 17000 / 35138 | train_loss 4.336 | train_ppl 76.434\n",
      "| epoch   0 | batch 17500 / 35138 | train_loss 5.425 | train_ppl 226.982\n",
      "| epoch   0 | batch 18000 / 35138 | train_loss 4.802 | train_ppl 121.811\n",
      "| epoch   0 | batch 18500 / 35138 | train_loss 5.729 | train_ppl 307.722\n",
      "| epoch   0 | batch 19000 / 35138 | train_loss 4.343 | train_ppl 76.922\n",
      "| epoch   0 | batch 19500 / 35138 | train_loss 5.089 | train_ppl 162.263\n",
      "| epoch   0 | batch 19997 / 35138 | train_loss 6.022 | train_ppl 412.401 | val_loss 5.336 | val_ppl 207.591\n",
      "old best ppl 232.10221731269863 new best ppl 207.59116973499027\n",
      "save model... no-teacher-forcing/model_ppl_207.59116973499027.model\n",
      "| epoch   0 | batch 20000 / 35138 | train_loss 4.817 | train_ppl 123.618\n",
      "| epoch   0 | batch 20500 / 35138 | train_loss 4.589 | train_ppl 98.359\n",
      "| epoch   0 | batch 21000 / 35138 | train_loss 4.606 | train_ppl 100.116\n",
      "| epoch   0 | batch 21500 / 35138 | train_loss 6.323 | train_ppl 557.015\n",
      "| epoch   0 | batch 22000 / 35138 | train_loss 5.024 | train_ppl 152.053\n",
      "| epoch   0 | batch 22500 / 35138 | train_loss 5.649 | train_ppl 283.928\n",
      "| epoch   0 | batch 23000 / 35138 | train_loss 4.682 | train_ppl 107.963\n",
      "| epoch   0 | batch 23500 / 35138 | train_loss 4.907 | train_ppl 135.196\n",
      "| epoch   0 | batch 24000 / 35138 | train_loss 5.047 | train_ppl 155.534\n",
      "| epoch   0 | batch 24500 / 35138 | train_loss 4.7 | train_ppl 109.984\n",
      "| epoch   0 | batch 24996 / 35138 | train_loss 5.421 | train_ppl 226.138 | val_loss 5.3 | val_ppl 200.432\n",
      "old best ppl 207.59116973499027 new best ppl 200.43172567537505\n",
      "save model... no-teacher-forcing/model_ppl_200.43172567537505.model\n",
      "| epoch   0 | batch 25000 / 35138 | train_loss 5.84 | train_ppl 343.842\n",
      "| epoch   0 | batch 25500 / 35138 | train_loss 6.177 | train_ppl 481.378\n",
      "| epoch   0 | batch 26000 / 35138 | train_loss 6.591 | train_ppl 728.484\n",
      "| epoch   0 | batch 26500 / 35138 | train_loss 5.407 | train_ppl 222.904\n",
      "| epoch   0 | batch 27000 / 35138 | train_loss 4.894 | train_ppl 133.51\n",
      "| epoch   0 | batch 27500 / 35138 | train_loss 5.346 | train_ppl 209.791\n",
      "| epoch   0 | batch 28000 / 35138 | train_loss 5.244 | train_ppl 189.384\n",
      "| epoch   0 | batch 28500 / 35138 | train_loss 5.261 | train_ppl 192.691\n",
      "| epoch   0 | batch 29000 / 35138 | train_loss 5.362 | train_ppl 213.242\n",
      "| epoch   0 | batch 29500 / 35138 | train_loss 6.129 | train_ppl 459.05\n",
      "| epoch   0 | batch 29995 / 35138 | train_loss 4.87 | train_ppl 130.333 | val_loss 5.434 | val_ppl 229.173\n",
      "| epoch   0 | batch 30000 / 35138 | train_loss 5.089 | train_ppl 162.153\n",
      "| epoch   0 | batch 30500 / 35138 | train_loss 5.405 | train_ppl 222.477\n",
      "| epoch   0 | batch 31000 / 35138 | train_loss 6.523 | train_ppl 680.385\n",
      "| epoch   0 | batch 31500 / 35138 | train_loss 5.606 | train_ppl 271.951\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-48746ccc0902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mmax_grad_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'no-teacher-forcing/model_ppl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       best_ppl = float('inf'))\n\u001b[0m",
      "\u001b[0;32m<ipython-input-66-a16995e8b8f5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, ep0, epN, train_iter, dev_iter, optimizer, criterion, max_grad_norm, model_name, best_ppl, teacher_forcing)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mnumber_of_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mtotal_loss_e\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnumber_of_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mtotal_number_of_words\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumber_of_words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
