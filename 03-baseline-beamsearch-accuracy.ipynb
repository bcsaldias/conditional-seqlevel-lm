{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import get_iterator, get_dataset\n",
    "from classifiers import theme_classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import GloVe \n",
    "GLOVE_EMBEDDING = GloVe(name=\"6B\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, review_text_FIELD, theme_FIELD = get_dataset(vectors = GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_iter = get_iterator(train_dataset, batch_size, train=True, shuffle=True, repeat=False)\n",
    "val_iter = get_iterator(val_dataset, batch_size, train=False, shuffle=True, repeat=False)\n",
    "test_iter = get_iterator(test_dataset, batch_size, train=False, shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transtaltion2string(raw_translations, target_vocab = review_text_FIELD, max_words=30000):\n",
    "    string_translations = []\n",
    "    for raw_sentence in raw_translations:\n",
    "        string_sentence = []\n",
    "        for i, word_idx in enumerate(raw_sentence):\n",
    "            if i == max_words: break\n",
    "            word = target_vocab.vocab.itos[word_idx]\n",
    "            if word == '<eos>':\n",
    "                break\n",
    "            if word != '<sos>':\n",
    "                string_sentence.append(word)\n",
    "        string_translations.append(string_sentence)\n",
    "\n",
    "    return string_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_words = []\n",
    "selected_labels = []\n",
    "lens = []\n",
    "if True:\n",
    "    for i, batch in enumerate(test_iter):\n",
    "        labels = batch.theme.cuda().long() - 1\n",
    "        batch = batch.review_text.cuda().long()\n",
    "        if batch.shape[0] > 3:\n",
    "            selected_labels += labels.tolist()\n",
    "            first_words += batch[1,:].tolist()\n",
    "            lens.append(batch.shape[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.592261904761905"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len = np.mean(lens)\n",
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other', 'plot', 'acting', 'effect', 'production']\n",
      "{0: 37614, 3: 2604, 1: 38078, 2: 6593, 4: 2454}\n"
     ]
    }
   ],
   "source": [
    "print(theme_FIELD.vocab.itos[1:])\n",
    "print(dict(Counter(selected_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87343 4519\n",
      "4481\n"
     ]
    }
   ],
   "source": [
    "# remove duplicates\n",
    "selected_first_words = list(set(first_words))\n",
    "print(len(first_words), len(selected_first_words))\n",
    "\n",
    "# clean for first words that are keywords\n",
    "first_words_text = transtaltion2string([list(selected_first_words)])[0]\n",
    "first_words_text = list(map(lambda x: theme_classifier(x) == 'other', first_words_text))\n",
    "selected_first_words = np.array(selected_first_words)[first_words_text].tolist()\n",
    "print(len(selected_first_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_list = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model import BaseModel, repackage_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./baseline/best_model_base_model_ppl_67.5461793533482.model', 'rb') as file:\n",
    "    model = torch.load(file)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 12304"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<sos>'\n",
    "EOS_WORD = '<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_next_n_words(self, first_word, label, max_len = 3, # ngram=3\n",
    "                            target_vocab = review_text_FIELD, top_k = 10):\n",
    "    self.eval()\n",
    "    with torch.no_grad():      \n",
    "\n",
    "        labels = torch.tensor([label]).cuda().long()\n",
    "        source = torch.tensor([first_word]).unsqueeze(1).cuda().long()\n",
    "        \n",
    "        eos_idx = target_vocab.vocab.stoi[EOS_WORD]\n",
    "        y_hat = source[:1,:]\n",
    "        y_hat = y_hat.unsqueeze(-1)\n",
    "\n",
    "        prediction_idxs = [[y_hat[0]]]\n",
    "        prediction_probs = [0]\n",
    "\n",
    "        next_hidden = [None]\n",
    "        \n",
    "        for t in range(max_len):\n",
    "            current_idxs = []\n",
    "            current_probs = []\n",
    "            current_hidd = [] \n",
    "\n",
    "            for k in range(y_hat.shape[-1]):\n",
    "                y_hat_k = y_hat[:,:,k]\n",
    "                current_hidd_k = next_hidden[k]\n",
    "                output, hidden = self(y_hat_k, labels, current_hidd_k)\n",
    "                current_hidd += [hidden]*top_k\n",
    "                top_probs, top_idx = output.topk(top_k, -1)\n",
    "                current_idxs.append(top_idx.squeeze(0).squeeze(0))\n",
    "                current_probs.append(top_probs.squeeze(0).squeeze(0))\n",
    "            current_idxs = torch.cat(current_idxs)\n",
    "            current_probs = torch.cat(current_probs)\n",
    "\n",
    "            next_args = torch.sort(current_probs, -1, True)[1][:top_k] \n",
    "\n",
    "            next_idxs, next_probs, next_hidden = [], [], []\n",
    "            tmp_pred_idxs, tmp_pred_probs = [], []\n",
    "            for idx in next_args:\n",
    "                chain_head = idx//top_k\n",
    "\n",
    "                next_idx = current_idxs[idx].int()\n",
    "                next_prob = current_probs[idx]\n",
    "                sentence_so_far = prediction_idxs[chain_head]\n",
    "                \n",
    "                if len(sentence_so_far)>0 and sentence_so_far[-1] == eos_idx:\n",
    "                    tmp_pred_idxs.append(sentence_so_far + [eos_idx])\n",
    "                    tmp_pred_probs.append(prediction_probs[chain_head])\n",
    "                else:\n",
    "                    tmp_pred_idxs.append(sentence_so_far + [next_idx])\n",
    "                    tmp_pred_probs.append(prediction_probs[chain_head] + next_prob)\n",
    "\n",
    "                next_idxs.append(next_idx.unsqueeze(0))\n",
    "                next_hidden.append(current_hidd[idx])\n",
    "\n",
    "            prediction_idxs = tmp_pred_idxs\n",
    "            prediction_probs = tmp_pred_probs\n",
    "            next_idxs = torch.cat(next_idxs)\n",
    "\n",
    "            y_hat = next_idxs.unsqueeze(0).unsqueeze(0).long()\n",
    "            \n",
    "        prediction_probs = torch.tensor(prediction_probs)\n",
    "        prediction_idxs = torch.tensor(prediction_idxs)\n",
    "        correct_order = torch.argsort(prediction_probs, descending=True).long()\n",
    "        \n",
    "        prediction_idxs = torch.index_select(prediction_idxs, 0, correct_order)\n",
    "\n",
    "        return prediction_idxs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>', 'other', 'plot', 'acting', 'effect', 'production']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#review_text_FIELD.vocab.itos\n",
    "theme_FIELD.vocab.itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.592261904761905"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 other\n",
      "0/4481\n",
      "50/4481\n",
      "100/4481\n",
      "150/4481\n",
      "200/4481\n",
      "250/4481\n",
      "300/4481\n",
      "350/4481\n",
      "400/4481\n",
      "450/4481\n",
      "500/4481\n",
      "550/4481\n",
      "600/4481\n",
      "650/4481\n",
      "700/4481\n",
      "750/4481\n",
      "800/4481\n",
      "850/4481\n",
      "900/4481\n",
      "950/4481\n",
      "1000/4481\n",
      "1050/4481\n",
      "1100/4481\n",
      "1150/4481\n",
      "1200/4481\n",
      "1250/4481\n",
      "1300/4481\n",
      "1350/4481\n",
      "1400/4481\n",
      "1450/4481\n",
      "1500/4481\n",
      "1550/4481\n",
      "1600/4481\n",
      "1650/4481\n",
      "1700/4481\n",
      "1750/4481\n",
      "1800/4481\n",
      "1850/4481\n",
      "1900/4481\n",
      "1950/4481\n",
      "2000/4481\n",
      "2050/4481\n",
      "2100/4481\n",
      "2150/4481\n",
      "2200/4481\n",
      "2250/4481\n",
      "2300/4481\n",
      "2350/4481\n",
      "2400/4481\n",
      "2450/4481\n",
      "2500/4481\n",
      "2550/4481\n",
      "2600/4481\n",
      "2650/4481\n",
      "2700/4481\n",
      "2750/4481\n",
      "2800/4481\n",
      "2850/4481\n",
      "2900/4481\n",
      "2950/4481\n",
      "3000/4481\n",
      "3050/4481\n",
      "3100/4481\n",
      "3150/4481\n",
      "3200/4481\n",
      "3250/4481\n",
      "3300/4481\n",
      "3350/4481\n",
      "3400/4481\n",
      "3450/4481\n",
      "3500/4481\n",
      "3550/4481\n",
      "3600/4481\n",
      "3650/4481\n",
      "3700/4481\n",
      "3750/4481\n",
      "3800/4481\n",
      "3850/4481\n",
      "3900/4481\n",
      "3950/4481\n",
      "4000/4481\n",
      "4050/4481\n",
      "4100/4481\n",
      "4150/4481\n",
      "4200/4481\n",
      "4250/4481\n",
      "4300/4481\n",
      "4350/4481\n",
      "4400/4481\n",
      "4450/4481\n",
      "1 plot\n",
      "0/4481\n",
      "50/4481\n",
      "100/4481\n",
      "150/4481\n",
      "200/4481\n",
      "250/4481\n",
      "300/4481\n",
      "350/4481\n",
      "400/4481\n",
      "450/4481\n",
      "500/4481\n",
      "550/4481\n",
      "600/4481\n",
      "650/4481\n",
      "700/4481\n",
      "750/4481\n",
      "800/4481\n",
      "850/4481\n",
      "900/4481\n",
      "950/4481\n",
      "1000/4481\n",
      "1050/4481\n",
      "1100/4481\n",
      "1150/4481\n",
      "1200/4481\n",
      "1250/4481\n",
      "1300/4481\n",
      "1350/4481\n",
      "1400/4481\n",
      "1450/4481\n",
      "1500/4481\n",
      "1550/4481\n",
      "1600/4481\n",
      "1650/4481\n",
      "1700/4481\n",
      "1750/4481\n",
      "1800/4481\n",
      "1850/4481\n",
      "1900/4481\n",
      "1950/4481\n",
      "2000/4481\n",
      "2050/4481\n",
      "2100/4481\n",
      "2150/4481\n",
      "2200/4481\n",
      "2250/4481\n",
      "2300/4481\n",
      "2350/4481\n",
      "2400/4481\n",
      "2450/4481\n",
      "2500/4481\n",
      "2550/4481\n",
      "2600/4481\n",
      "2650/4481\n",
      "2700/4481\n",
      "2750/4481\n",
      "2800/4481\n",
      "2850/4481\n",
      "2900/4481\n",
      "2950/4481\n",
      "3000/4481\n",
      "3050/4481\n",
      "3100/4481\n",
      "3150/4481\n",
      "3200/4481\n",
      "3250/4481\n",
      "3300/4481\n",
      "3350/4481\n",
      "3400/4481\n",
      "3450/4481\n",
      "3500/4481\n",
      "3550/4481\n",
      "3600/4481\n",
      "3650/4481\n",
      "3700/4481\n",
      "3750/4481\n",
      "3800/4481\n",
      "3850/4481\n",
      "3900/4481\n",
      "3950/4481\n",
      "4000/4481\n",
      "4050/4481\n",
      "4100/4481\n",
      "4150/4481\n",
      "4200/4481\n",
      "4250/4481\n",
      "4300/4481\n",
      "4350/4481\n",
      "4400/4481\n",
      "4450/4481\n",
      "2 acting\n",
      "0/4481\n",
      "50/4481\n",
      "100/4481\n",
      "150/4481\n",
      "200/4481\n",
      "250/4481\n",
      "300/4481\n",
      "350/4481\n",
      "400/4481\n",
      "450/4481\n",
      "500/4481\n",
      "550/4481\n",
      "600/4481\n",
      "650/4481\n",
      "700/4481\n",
      "750/4481\n",
      "800/4481\n",
      "850/4481\n",
      "900/4481\n",
      "950/4481\n",
      "1000/4481\n",
      "1050/4481\n",
      "1100/4481\n",
      "1150/4481\n",
      "1200/4481\n",
      "1250/4481\n",
      "1300/4481\n",
      "1350/4481\n",
      "1400/4481\n",
      "1450/4481\n",
      "1500/4481\n",
      "1550/4481\n",
      "1600/4481\n",
      "1650/4481\n",
      "1700/4481\n",
      "1750/4481\n",
      "1800/4481\n",
      "1850/4481\n",
      "1900/4481\n",
      "1950/4481\n",
      "2000/4481\n",
      "2050/4481\n",
      "2100/4481\n",
      "2150/4481\n",
      "2200/4481\n",
      "2250/4481\n",
      "2300/4481\n",
      "2350/4481\n",
      "2400/4481\n",
      "2450/4481\n",
      "2500/4481\n",
      "2550/4481\n",
      "2600/4481\n",
      "2650/4481\n",
      "2700/4481\n",
      "2750/4481\n",
      "2800/4481\n",
      "2850/4481\n",
      "2900/4481\n",
      "2950/4481\n",
      "3000/4481\n",
      "3050/4481\n",
      "3100/4481\n",
      "3150/4481\n",
      "3200/4481\n",
      "3250/4481\n",
      "3300/4481\n",
      "3350/4481\n",
      "3400/4481\n",
      "3450/4481\n",
      "3500/4481\n",
      "3550/4481\n",
      "3600/4481\n",
      "3650/4481\n",
      "3700/4481\n",
      "3750/4481\n",
      "3800/4481\n",
      "3850/4481\n",
      "3900/4481\n",
      "3950/4481\n",
      "4000/4481\n",
      "4050/4481\n",
      "4100/4481\n",
      "4150/4481\n",
      "4200/4481\n",
      "4250/4481\n",
      "4300/4481\n",
      "4350/4481\n",
      "4400/4481\n",
      "4450/4481\n",
      "3 effect\n",
      "0/4481\n",
      "50/4481\n",
      "100/4481\n",
      "150/4481\n",
      "200/4481\n",
      "250/4481\n",
      "300/4481\n",
      "350/4481\n",
      "400/4481\n",
      "450/4481\n",
      "500/4481\n",
      "550/4481\n",
      "600/4481\n",
      "650/4481\n",
      "700/4481\n",
      "750/4481\n",
      "800/4481\n",
      "850/4481\n",
      "900/4481\n",
      "950/4481\n",
      "1000/4481\n",
      "1050/4481\n",
      "1100/4481\n",
      "1150/4481\n",
      "1200/4481\n",
      "1250/4481\n",
      "1300/4481\n",
      "1350/4481\n",
      "1400/4481\n",
      "1450/4481\n",
      "1500/4481\n",
      "1550/4481\n",
      "1600/4481\n",
      "1650/4481\n",
      "1700/4481\n",
      "1750/4481\n",
      "1800/4481\n",
      "1850/4481\n",
      "1900/4481\n",
      "1950/4481\n",
      "2000/4481\n",
      "2050/4481\n",
      "2100/4481\n",
      "2150/4481\n",
      "2200/4481\n",
      "2250/4481\n",
      "2300/4481\n",
      "2350/4481\n",
      "2400/4481\n",
      "2450/4481\n",
      "2500/4481\n",
      "2550/4481\n",
      "2600/4481\n",
      "2650/4481\n",
      "2700/4481\n",
      "2750/4481\n",
      "2800/4481\n",
      "2850/4481\n",
      "2900/4481\n",
      "2950/4481\n",
      "3000/4481\n",
      "3050/4481\n",
      "3100/4481\n",
      "3150/4481\n",
      "3200/4481\n",
      "3250/4481\n",
      "3300/4481\n",
      "3350/4481\n",
      "3400/4481\n",
      "3450/4481\n",
      "3500/4481\n",
      "3550/4481\n",
      "3600/4481\n",
      "3650/4481\n",
      "3700/4481\n",
      "3750/4481\n",
      "3800/4481\n",
      "3850/4481\n",
      "3900/4481\n",
      "3950/4481\n",
      "4000/4481\n",
      "4050/4481\n",
      "4100/4481\n",
      "4150/4481\n",
      "4200/4481\n",
      "4250/4481\n",
      "4300/4481\n",
      "4350/4481\n",
      "4400/4481\n",
      "4450/4481\n",
      "4 production\n",
      "0/4481\n",
      "50/4481\n",
      "100/4481\n",
      "150/4481\n",
      "200/4481\n",
      "250/4481\n",
      "300/4481\n",
      "350/4481\n",
      "400/4481\n",
      "450/4481\n",
      "500/4481\n",
      "550/4481\n",
      "600/4481\n",
      "650/4481\n",
      "700/4481\n",
      "750/4481\n",
      "800/4481\n",
      "850/4481\n",
      "900/4481\n",
      "950/4481\n",
      "1000/4481\n",
      "1050/4481\n",
      "1100/4481\n",
      "1150/4481\n",
      "1200/4481\n",
      "1250/4481\n",
      "1300/4481\n",
      "1350/4481\n",
      "1400/4481\n",
      "1450/4481\n",
      "1500/4481\n",
      "1550/4481\n",
      "1600/4481\n",
      "1650/4481\n",
      "1700/4481\n",
      "1750/4481\n",
      "1800/4481\n",
      "1850/4481\n",
      "1900/4481\n",
      "1950/4481\n",
      "2000/4481\n",
      "2050/4481\n",
      "2100/4481\n",
      "2150/4481\n",
      "2200/4481\n",
      "2250/4481\n",
      "2300/4481\n",
      "2350/4481\n",
      "2400/4481\n",
      "2450/4481\n",
      "2500/4481\n",
      "2550/4481\n",
      "2600/4481\n",
      "2650/4481\n",
      "2700/4481\n",
      "2750/4481\n",
      "2800/4481\n",
      "2850/4481\n",
      "2900/4481\n",
      "2950/4481\n",
      "3000/4481\n",
      "3050/4481\n",
      "3100/4481\n",
      "3150/4481\n",
      "3200/4481\n",
      "3250/4481\n",
      "3300/4481\n",
      "3350/4481\n",
      "3400/4481\n",
      "3450/4481\n",
      "3500/4481\n",
      "3550/4481\n",
      "3600/4481\n",
      "3650/4481\n",
      "3700/4481\n",
      "3750/4481\n",
      "3800/4481\n",
      "3850/4481\n",
      "3900/4481\n",
      "3950/4481\n",
      "4000/4481\n",
      "4050/4481\n",
      "4100/4481\n",
      "4150/4481\n",
      "4200/4481\n",
      "4250/4481\n",
      "4300/4481\n",
      "4350/4481\n",
      "4400/4481\n",
      "4450/4481\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for lid, label in enumerate(theme_FIELD.vocab.itos[1:]):\n",
    "    print(lid, label)\n",
    "    for wid, word0 in enumerate(selected_first_words):\n",
    "        if wid % 50 == 0 : print('{}/{}'.format(wid, len(selected_first_words)))\n",
    "        pred, label = generate_next_n_words(model, word0, lid, max_len=20, top_k=1) #int(avg_len)\n",
    "        pred = transtaltion2string(pred[:1])\n",
    "        string = ' '.join(pred[0])\n",
    "        predicted_class = theme_classifier(string)\n",
    "        results.append([theme_FIELD.vocab.itos[label+1], string, predicted_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = pd.DataFrame(results, columns=['true_label', 'generation', 'predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = DF[DF.generation.apply(lambda x: x.split()[0] != '<unk>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.to_csv('DF20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['other', 'plot', 'acting', 'effect', 'production'], dtype=object)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.true_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 1c - global acc score\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7670089285714285"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('baseline 1c - global acc score')\n",
    "(DF.true_label == DF.predicted).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 1c - acc score per class\n",
      "other 0.9716517857142857\n",
      "plot 0.5696428571428571\n",
      "acting 0.8479910714285714\n",
      "effect 0.5810267857142857\n",
      "production 0.8647321428571428\n"
     ]
    }
   ],
   "source": [
    "print('baseline 1c - acc score per class')\n",
    "for case in DF.true_label.unique():\n",
    "    print(case, (DF[DF.true_label==case].true_label == DF[DF.true_label==case].predicted).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(DF.true_label, DF.predicted, labels=DF.true_label.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline 1c - confusion matrix\n",
      "['other' 'plot' 'acting' 'effect' 'production']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.97, 0.02, 0.  , 0.01, 0.  ],\n",
       "       [0.43, 0.57, 0.  , 0.  , 0.  ],\n",
       "       [0.14, 0.01, 0.85, 0.  , 0.  ],\n",
       "       [0.41, 0.01, 0.  , 0.58, 0.  ],\n",
       "       [0.13, 0.  , 0.  , 0.  , 0.86]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('baseline 1c - confusion matrix')\n",
    "print(DF.true_label.unique())\n",
    "(cm / cm.sum(-1)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
