{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generators import get_iterator, get_dataset\n",
    "from classifiers import theme_classifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import GloVe \n",
    "GLOVE_EMBEDDING = GloVe(name=\"6B\", dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset, review_text_FIELD, theme_FIELD = get_dataset(vectors = GLOVE_EMBEDDING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "train_iter = get_iterator(train_dataset, batch_size, train=True, shuffle=True, repeat=False)\n",
    "val_iter = get_iterator(val_dataset, batch_size, train=False, shuffle=True, repeat=False)\n",
    "test_iter = get_iterator(test_dataset, batch_size, train=False, shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_source, criterion):\n",
    "    model.eval()\n",
    "    total_loss_e = 0\n",
    "    total_number_of_words = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(data_source):\n",
    "            labels = batch.theme.cuda().long() - 1\n",
    "            batch = batch.review_text.cuda().long()\n",
    "            hidden = None\n",
    "            if batch.shape[0] > 3:\n",
    "                data, targets = batch[1:-1,:], batch[2:,:]\n",
    "                \n",
    "                output, hidden = model(data, labels, hidden)\n",
    "                output_flat = output.contiguous().view(-1, vocab_size)\n",
    "                target_flat = targets.contiguous().view(-1)\n",
    "                batch_loss = criterion(output_flat, target_flat).detach().item()\n",
    "\n",
    "                number_of_words = data.shape[0] * data.shape[1]\n",
    "                total_loss_e += batch_loss * number_of_words\n",
    "                total_number_of_words += number_of_words\n",
    "\n",
    "                repackage_hidden(hidden)\n",
    "            \n",
    "    return total_loss_e / total_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_model import BaseModel, repackage_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./baseline/best_model_base_model_ppl_67.5461793533482.model', 'rb') as file:\n",
    "    model = torch.load(file)\n",
    "    model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(reduction='mean',\n",
    "                       ignore_index=train_dataset.fields[\"review_text\"].vocab.stoi['<pad>']).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 12304\n",
    "test_error = evaluate(model, test_iter, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.206123341756414, 67.09592700457719)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_error, np.exp(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOS_WORD = '<sos>'\n",
    "EOS_WORD = '<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_translation(self, source, idx, max_len = MAX_LEN, # ngram=3\n",
    "                            target_vocab = review_text_FIELD, top_k = 5):\n",
    "\n",
    "    self.eval()\n",
    "    with torch.no_grad():      \n",
    "\n",
    "        labels = source.theme.cuda().long() - 1\n",
    "        source = source.review_text.cuda().long()\n",
    "        \n",
    "        labels = labels[idx].unsqueeze(0)\n",
    "        source = source[:,idx].unsqueeze(1)\n",
    "        \n",
    "        batch_size = source.shape[1] \n",
    "        assert batch_size == 1\n",
    "        \n",
    "        eos_idx = target_vocab.vocab.stoi[EOS_WORD]\n",
    "        y_hat = source[:1,:]\n",
    "        y_hat = y_hat.unsqueeze(-1)\n",
    "\n",
    "        #print(y_hat[0])\n",
    "        prediction_idxs = [[y_hat[0]]] #[[]] #bos_idx\n",
    "        prediction_probs = [0]\n",
    "\n",
    "        if source.shape[0] > 3:\n",
    "            data, targets = source[1:-1,:], source[2:,:]\n",
    "        else:\n",
    "            return prediction_idxs\n",
    "        \n",
    "        #encoder_output, hidden = self.encoder(source)\n",
    "        #hidden = (hidden[0][-1:], hidden[1][-1:])\n",
    "        next_hidden = [None]\n",
    "        \n",
    "        for t in range(max_len):\n",
    "            current_idxs = []\n",
    "            current_probs = []\n",
    "            current_hidd = [] \n",
    "\n",
    "            for k in range(y_hat.shape[-1]):\n",
    "                y_hat_k = y_hat[:,:,k]\n",
    "                current_hidd_k = next_hidden[k]\n",
    "                output, hidden = self(y_hat_k, labels, current_hidd_k)\n",
    "                current_hidd += [hidden]*top_k\n",
    "                top_probs, top_idx = output.topk(top_k, -1)\n",
    "                current_idxs.append(top_idx.squeeze(0).squeeze(0))\n",
    "                current_probs.append(top_probs.squeeze(0).squeeze(0))\n",
    "            current_idxs = torch.cat(current_idxs)\n",
    "            current_probs = torch.cat(current_probs)\n",
    "\n",
    "            next_args = torch.sort(current_probs, -1, True)[1][:top_k] \n",
    "\n",
    "            next_idxs, next_probs, next_hidden = [], [], []\n",
    "            tmp_pred_idxs, tmp_pred_probs = [], []\n",
    "            for idx in next_args:\n",
    "                chain_head = idx//top_k\n",
    "\n",
    "                next_idx = current_idxs[idx].int()\n",
    "                next_prob = current_probs[idx]\n",
    "                sentence_so_far = prediction_idxs[chain_head]\n",
    "                \n",
    "                if len(sentence_so_far)>0 and sentence_so_far[-1] == eos_idx:\n",
    "                    tmp_pred_idxs.append(sentence_so_far + [eos_idx])\n",
    "                    tmp_pred_probs.append(prediction_probs[chain_head])\n",
    "                else:\n",
    "                    tmp_pred_idxs.append(sentence_so_far + [next_idx])\n",
    "                    tmp_pred_probs.append(prediction_probs[chain_head] + next_prob)\n",
    "\n",
    "                next_idxs.append(next_idx.unsqueeze(0))\n",
    "                next_hidden.append(current_hidd[idx])\n",
    "\n",
    "            prediction_idxs = tmp_pred_idxs\n",
    "            prediction_probs = tmp_pred_probs\n",
    "            next_idxs = torch.cat(next_idxs)\n",
    "\n",
    "            y_hat = next_idxs.unsqueeze(0).unsqueeze(0).long()\n",
    "            \n",
    "        prediction_probs = torch.tensor(prediction_probs)\n",
    "        prediction_idxs = torch.tensor(prediction_idxs)\n",
    "        correct_order = torch.argsort(prediction_probs, descending=True).long()\n",
    "        \n",
    "        prediction_idxs = torch.index_select(prediction_idxs, 0, correct_order)\n",
    "\n",
    "        return prediction_idxs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 20])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list[100].review_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transtaltion2string(raw_translations, target_vocab = review_text_FIELD, max_words=30000):\n",
    "    string_translations = []\n",
    "    for raw_sentence in raw_translations:\n",
    "        string_sentence = []\n",
    "        for i, word_idx in enumerate(raw_sentence):\n",
    "            if i == max_words: break\n",
    "            word = target_vocab.vocab.itos[word_idx]\n",
    "            if word == '<eos>':\n",
    "                break\n",
    "            if word != '<sos>':\n",
    "                string_sentence.append(word)\n",
    "        string_translations.append(string_sentence)\n",
    "\n",
    "    return string_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([[7]])]]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam_search_translation(model, 7, 3, max_len=20, top_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
      "       device='cuda:0') torch.Size([6, 20])\n",
      "tensor([1], device='cuda:0') torch.Size([6, 1])\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-cf3166408675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search_translation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranstaltion2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-242-8d88262f2b1a>\u001b[0m in \u001b[0;36mbeam_search_translation\u001b[0;34m(self, source, idx, max_len, target_vocab, top_k)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0;36m0\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    pred, label = beam_search_translation(model, test_list[200], idx = i, max_len=20, top_k=10)\n",
    "    print(pred[:1])\n",
    "    pred = transtaltion2string(pred[:1])\n",
    "    string = ' '.join(pred[0])\n",
    "    predicted_class = theme_classifier(string)\n",
    "    print(theme_FIELD.vocab.itos[label+1], '|', string, '|', predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transtaltion2string(test_list[200].review_text[1,:].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
